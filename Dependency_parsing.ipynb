{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import DependencyGraph, DependencyEvaluator\n",
    "from nltk.parse.transitionparser import TransitionParser, Configuration, Transition\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import svm, linear_model,neural_network\n",
    "\n",
    "\n",
    "import pickle\n",
    "import tempfile\n",
    "import os\n",
    "from numpy import array\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/anaconda3/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "f = DependencyGraph.load(\"./UD_Hindi/hi-ud-train.conllu\")\n",
    "conf = Configuration(f[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating files for train & test (with & without the morphological feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Data\n",
    "file1 = open('./UD_Hindi/with_mor_train.conllu',\"w+\")\n",
    "file2 = open('./UD_Hindi/without_mor_train.conllu',\"w+\")\n",
    "with open(\"./UD_Hindi/hi-ud-train.conllu\",\"r+\",encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if(line == '\\n'):\n",
    "            file1.write(line)\n",
    "            file2.write(line)\n",
    "        else:\n",
    "            line = line.split('\\t')\n",
    "            line1 = list(line)\n",
    "            line1[5] = line1[5]+\"|\"+line1[9][:-1]\n",
    "            line[5] = \"_\"\n",
    "            line = '\\t'.join(line)\n",
    "            line1 = '\\t'.join(line1)\n",
    "            file1.write(line1)\n",
    "            file2.write(line)\n",
    "file1.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "file1 = open('./UD_Hindi/with_mor_test.conllu',\"w+\")\n",
    "file2 = open('./UD_Hindi/without_mor_test.conllu',\"w+\")\n",
    "with open(\"./UD_Hindi/hi-ud-test.conllu\",\"r+\",encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if(line == '\\n'):\n",
    "            file1.write(line)\n",
    "            file2.write(line)\n",
    "        else:\n",
    "            line = line.split('\\t')\n",
    "            line1 = list(line)\n",
    "            line1[5] = line1[5]+\"|\"+line1[9][:-1]\n",
    "            line[5] = \"_\"\n",
    "            line = '\\t'.join(line)\n",
    "            line1 = '\\t'.join(line1)\n",
    "            file1.write(line1)\n",
    "            file2.write(line)\n",
    "file1.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainTransitionParser(TransitionParser):\n",
    "    def train(self, dgraphs, modelfile, classifier=\"None\",verbose=True):\n",
    "        \"\"\"\n",
    "        :param dgraphs : List of training DependencyGraph \n",
    "        :param modelfile : Saves the trained model in the given file\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            input_file = tempfile.NamedTemporaryFile(prefix='transition_parse.train',\n",
    "                                                    dir=tempfile.gettempdir(),delete=False)\n",
    "\n",
    "            if self._algorithm == self.ARC_STANDARD:\n",
    "                self._create_training_examples_arc_std(dgraphs, input_file)\n",
    "            else:\n",
    "                self._create_training_examples_arc_eager(dgraphs, input_file)\n",
    "\n",
    "            input_file.close()\n",
    "\n",
    "            x_train, y_train = load_svmlight_file(input_file.name)\n",
    "\n",
    "            if(classifier == \"svm\"):\n",
    "                model = svm.SVC(kernel='poly',degree=2,coef0=0,gamma=0.2,C=0.5,verbose=verbose,probability=True)\n",
    "            elif(classifier == \"logistic\"):\n",
    "                model = linear_model.LogisticRegression(C=0.7,solver='lbfgs',verbose=verbose)\n",
    "            elif(classifier == \"mlp\"):\n",
    "                model = neural_network.MLPClassifier(hidden_layer_sizes=(150,75,),learning_rate='adaptive',max_iter=1000)\n",
    "            model.fit(x_train, y_train)\n",
    "            \n",
    "            pickle.dump(model, open(modelfile, 'wb'))\n",
    "            \n",
    "        finally:\n",
    "            os.remove(input_file.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Morphological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/anaconda3/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "graph_mor_train = DependencyGraph.load(\"./UD_Hindi/with_mor_train.conllu\")\n",
    "graph_mor_test = DependencyGraph.load(\"./UD_Hindi/with_mor_test.conllu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc-Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.9130763416477702, 0.8329554043839759)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_mor_std_svm = MainTransitionParser('arc-standard')\n",
    "parser_mor_std_svm.train(graph_mor_train,'./UD_Hindi/temp.arcstd_mor_svm.model',classifier = \"svm\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_mor_std_svm = parser_mor_std_svm.parse(graph_mor_test, './UD_Hindi/temp.arcstd_mor_svm.model')\n",
    "eval_mor_std_svm = DependencyEvaluator(result_mor_std_svm, graph_mor_test)\n",
    "print(eval_mor_std_svm.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8684807256235828, 0.7709750566893424)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_mor_std_log = MainTransitionParser('arc-standard')\n",
    "parser_mor_std_log.train(graph_mor_train,'./UD_Hindi/temp.arcstd_mor_log.model', classifier = \"logistic\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_mor_std_log = parser_mor_std_log.parse(graph_mor_test, './UD_Hindi/temp.arcstd_mor_log.model')\n",
    "eval_mor_std_log = DependencyEvaluator(result_mor_std_log, graph_mor_test)\n",
    "print(eval_mor_std_log.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8594104308390023, 0.7619047619047619)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_mor_std_mlp = MainTransitionParser('arc-standard')\n",
    "parser_mor_std_mlp.train(graph_mor_train,'./UD_Hindi/temp.arcstd_mor_mlp.model', classifier = \"mlp\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_mor_std_mlp = parser_mor_std_mlp.parse(graph_mor_test, './UD_Hindi/temp.arcstd_mor_mlp.model')\n",
    "eval_mor_std_mlp = DependencyEvaluator(result_mor_std_mlp, graph_mor_test)\n",
    "print(eval_mor_std_mlp.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc-Eager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.9115646258503401, 0.8253968253968254)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_mor_eag_svm = MainTransitionParser('arc-eager')\n",
    "parser_mor_eag_svm.train(graph_mor_train,'./UD_Hindi/temp.arceag_mor_svm.model',classifier = \"svm\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_mor_eag_svm = parser_mor_eag_svm.parse(graph_mor_test, './UD_Hindi/temp.arceag_mor_svm.model')\n",
    "eval_mor_eag_svm = DependencyEvaluator(result_mor_eag_svm, graph_mor_test)\n",
    "print(eval_mor_eag_svm.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.9040060468631897, 0.8057445200302343)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_mor_eag_log = MainTransitionParser('arc-eager')\n",
    "parser_mor_eag_log.train(graph_mor_train,'./UD_Hindi/temp.arceag_mor_log.model', classifier = \"logistic\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_mor_eag_log = parser_mor_eag_log.parse(graph_mor_test, './UD_Hindi/temp.arceag_mor_log.model')\n",
    "eval_mor_eag_log = DependencyEvaluator(result_mor_eag_log, graph_mor_test)\n",
    "print(eval_mor_eag_log.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8684807256235828, 0.764928193499622)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_mor_eag_mlp = MainTransitionParser('arc-eager')\n",
    "parser_mor_eag_mlp.train(graph_mor_train,'./UD_Hindi/temp.arceag_mor_mlp.model', classifier = \"mlp\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_mor_eag_mlp = parser_mor_eag_mlp.parse(graph_mor_test, './UD_Hindi/temp.arceag_mor_mlp.model')\n",
    "eval_mor_eag_mlp = DependencyEvaluator(result_mor_eag_mlp, graph_mor_test)\n",
    "print(eval_mor_eag_mlp.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Morphological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/anaconda3/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "graph_train = DependencyGraph.load(\"./UD_Hindi/without_mor_train.conllu\")\n",
    "graph_test = DependencyGraph.load(\"./UD_Hindi/without_mor_test.conllu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc-Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8465608465608465, 0.762660619803477)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_std_svm = MainTransitionParser('arc-standard')\n",
    "parser_std_svm.train(graph_train,'./UD_Hindi/temp.arcstd_svm.model', classifier = \"svm\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_std_svm = parser_std_svm.parse(graph_test, './UD_Hindi/temp.arcstd_svm.model')\n",
    "eval_std_svm = DependencyEvaluator(result_std_svm, graph_test)\n",
    "print(eval_std_svm.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.7974300831443688, 0.6863189720332578)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_std_log = MainTransitionParser('arc-standard')\n",
    "parser_std_log.train(graph_train,'./UD_Hindi/temp.arcstd_log.model', classifier = \"logistic\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_std_log = parser_std_log.parse(graph_test, './UD_Hindi/temp.arcstd_log.model')\n",
    "eval_std_log = DependencyEvaluator(result_std_log, graph_test)\n",
    "print(eval_std_log.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8019652305366591, 0.6878306878306878)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_std_mlp = MainTransitionParser('arc-standard')\n",
    "parser_std_mlp.train(graph_train,'./UD_Hindi/temp.arcstd_mlp.model', classifier = \"mlp\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_std_mlp = parser_std_mlp.parse(graph_test, './UD_Hindi/temp.arcstd_mlp.model')\n",
    "eval_std_mlp = DependencyEvaluator(result_std_mlp, graph_test)\n",
    "print(eval_std_mlp.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arc-Eager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.871504157218443, 0.7732426303854876)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_eag_svm = MainTransitionParser('arc-eager')\n",
    "parser_eag_svm.train(graph_train,'./UD_Hindi/temp.arceag_svm.model',classifier=\"svm\",verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_eag_svm = parser_eag_svm.parse(graph_test, './UD_Hindi/temp.arceag_svm.model')\n",
    "eval_eag_svm = DependencyEvaluator(result_eag_svm, graph_test)\n",
    "print(eval_eag_svm.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8473167044595616, 0.7309145880574452)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_eag_log = MainTransitionParser('arc-eager')\n",
    "parser_eag_log.train(graph_train,'./UD_Hindi/temp.arceag_log.model', classifier = \"logistic\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_eag_log = parser_eag_log.parse(graph_test, './UD_Hindi/temp.arceag_log.model')\n",
    "eval_eag_log = DependencyEvaluator(result_eag_log, graph_test)\n",
    "print(eval_eag_log.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "(0.8291761148904006, 0.7052154195011338)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "parser_eag_mlp = MainTransitionParser('arc-eager')\n",
    "parser_eag_mlp.train(graph_train,'./UD_Hindi/temp.arceag_mlp.model', classifier = \"mlp\", verbose=False)\n",
    "\n",
    "#Testing\n",
    "result_eag_mlp = parser_eag_mlp.parse(graph_test, './UD_Hindi/temp.arceag_mlp.model')\n",
    "eval_eag_mlp = DependencyEvaluator(result_eag_mlp, graph_test)\n",
    "print(eval_eag_mlp.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
